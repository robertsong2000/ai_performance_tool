#!/usr/bin/env python3
"""
LM Studio AIæ¨ç†æ€§èƒ½æµ‹è¯•ä¸»ç¨‹åº
æ”¯æŒå¤šç§æµ‹è¯•æ¨¡å¼ï¼šå•æ¬¡æµ‹è¯•ã€æ‰¹é‡æµ‹è¯•ã€å¹¶å‘æµ‹è¯•ã€å‹åŠ›æµ‹è¯•
"""

import argparse
import sys
from lm_studio_tester import LMStudioPerformanceTester, get_test_prompts


def run_single_test(tester: LMStudioPerformanceTester):
    """è¿è¡Œå•æ¬¡æ¨ç†æµ‹è¯•"""
    print("\nğŸ” å•æ¬¡æ¨ç†æµ‹è¯•")
    print("-" * 40)
    
    prompt = "è¯·ç®€å•ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µï¼Œä¸è¶…è¿‡100å­—ã€‚"
    print(f"ğŸ“ æµ‹è¯•æç¤ºè¯: {prompt}")
    
    metrics = tester.single_inference_test(prompt, max_tokens=150)
    if metrics:
        print(f"âœ… æµ‹è¯•å®Œæˆ!")
        print(f"   å“åº”æ—¶é—´: {metrics.response_time:.3f}ç§’")
        print(f"   ç”Ÿæˆé€Ÿåº¦: {metrics.tokens_per_second:.2f} tokens/ç§’")
        print(f"   ç”ŸæˆTokenæ•°: {metrics.completion_tokens}")
        print(f"   å†…å­˜ä½¿ç”¨: {metrics.memory_usage:.1f} MB")
        print(f"   CPUä½¿ç”¨ç‡: {metrics.cpu_usage:.1f}%")
    else:
        print("âŒ å•æ¬¡æµ‹è¯•å¤±è´¥")


def run_batch_test(tester: LMStudioPerformanceTester):
    """è¿è¡Œæ‰¹é‡æ¨ç†æµ‹è¯•"""
    print("\nğŸ“¦ æ‰¹é‡æ¨ç†æµ‹è¯•")
    print("-" * 40)
    
    prompts = get_test_prompts()[:5]  # ä½¿ç”¨å‰5ä¸ªæµ‹è¯•æç¤ºè¯
    results = tester.batch_inference_test(prompts, max_tokens=100)
    
    if results:
        avg_response_time = sum(r.response_time for r in results) / len(results)
        avg_tps = sum(r.tokens_per_second for r in results) / len(results)
        print(f"\nğŸ“Š æ‰¹é‡æµ‹è¯•æ±‡æ€»:")
        print(f"   æˆåŠŸè¯·æ±‚: {len(results)}/{len(prompts)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}ç§’")
        print(f"   å¹³å‡ç”Ÿæˆé€Ÿåº¦: {avg_tps:.2f} tokens/ç§’")


def run_concurrent_test(tester: LMStudioPerformanceTester):
    """è¿è¡Œå¹¶å‘æ¨ç†æµ‹è¯•"""
    print("\nğŸ”„ å¹¶å‘æ¨ç†æµ‹è¯•")
    print("-" * 40)
    
    prompt = "è¯·ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯æ·±åº¦å­¦ä¹ ã€‚"
    concurrent_count = 3  # å¹¶å‘æ•°é‡
    
    results = tester.concurrent_inference_test(prompt, num_concurrent=concurrent_count, max_tokens=80)
    
    if results:
        avg_response_time = sum(r.response_time for r in results) / len(results)
        total_tps = sum(r.tokens_per_second for r in results)
        print(f"\nğŸ“Š å¹¶å‘æµ‹è¯•æ±‡æ€»:")
        print(f"   å¹¶å‘æ•°: {concurrent_count}")
        print(f"   æˆåŠŸè¯·æ±‚: {len(results)}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.3f}ç§’")
        print(f"   æ€»ååé‡: {total_tps:.2f} tokens/ç§’")


def run_stress_test(tester: LMStudioPerformanceTester):
    """è¿è¡Œå‹åŠ›æµ‹è¯•"""
    print("\nâš¡ å‹åŠ›æµ‹è¯•")
    print("-" * 40)
    
    prompt = "ç®€å•å›ç­”ï¼šä»€ä¹ˆæ˜¯AIï¼Ÿ"
    duration = 30  # æµ‹è¯•30ç§’
    
    print(f"â±ï¸  å°†è¿›è¡Œ {duration} ç§’çš„å‹åŠ›æµ‹è¯•...")
    results = tester.stress_test(prompt, duration_seconds=duration, max_tokens=50)
    
    if results:
        success_rate = len(results) / duration * 100  # æ¯ç§’æˆåŠŸè¯·æ±‚æ•°
        avg_tps = sum(r.tokens_per_second for r in results) / len(results)
        print(f"\nğŸ“Š å‹åŠ›æµ‹è¯•æ±‡æ€»:")
        print(f"   æµ‹è¯•æ—¶é•¿: {duration}ç§’")
        print(f"   æˆåŠŸè¯·æ±‚: {len(results)}")
        print(f"   å¹³å‡æ¯ç§’è¯·æ±‚æ•°: {len(results)/duration:.2f}")
        print(f"   å¹³å‡ç”Ÿæˆé€Ÿåº¦: {avg_tps:.2f} tokens/ç§’")


def run_comprehensive_test(tester: LMStudioPerformanceTester):
    """è¿è¡Œç»¼åˆæµ‹è¯•"""
    print("\nğŸ¯ ç»¼åˆæ€§èƒ½æµ‹è¯•")
    print("=" * 50)
    
    # ä¾æ¬¡è¿è¡Œå„ç§æµ‹è¯•
    run_single_test(tester)
    run_batch_test(tester)
    run_concurrent_test(tester)
    run_stress_test(tester)
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "=" * 50)
    tester.print_report()
    
    # ä¿å­˜è¯¦ç»†ç»“æœ
    tester.save_detailed_results()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="LM Studio AIæ¨ç†æ€§èƒ½æµ‹è¯•å·¥å…·")
    parser.add_argument("--url", default="http://localhost:1234", 
                       help="LM StudioæœåŠ¡å™¨åœ°å€ (é»˜è®¤: http://localhost:1234)")
    parser.add_argument("--model", default=None, 
                       help="æŒ‡å®šæ¨¡å‹åç§° (å¯é€‰)")
    parser.add_argument("--test-type", choices=["single", "batch", "concurrent", "stress", "comprehensive"], 
                       default="comprehensive", help="æµ‹è¯•ç±»å‹ (é»˜è®¤: comprehensive)")
    parser.add_argument("--list", action="store_true",
                       help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹")
    
    args = parser.parse_args()
    
    print("ğŸš€ LM Studio AIæ¨ç†æ€§èƒ½æµ‹è¯•å·¥å…·")
    print("=" * 50)
    print(f"ğŸŒ æœåŠ¡å™¨åœ°å€: {args.url}")
    if args.model:
        print(f"ğŸ¤– æŒ‡å®šæ¨¡å‹: {args.model}")
    print(f"ğŸ§ª æµ‹è¯•ç±»å‹: {args.test_type}")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å™¨å®ä¾‹
    tester = LMStudioPerformanceTester(base_url=args.url, model_name=args.model)
    
    # å¦‚æœä½¿ç”¨äº†--listé€‰é¡¹ï¼Œåˆ™åªåˆ—å‡ºæ¨¡å‹å¹¶é€€å‡º
    if args.list:
        models = tester.get_available_models()
        if models:
            print("\nğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨:")
            for i, model in enumerate(models, 1):
                print(f"   {i}. {model}")
        else:
            print("\nâŒ æ— æ³•è·å–æ¨¡å‹åˆ—è¡¨ï¼Œè¯·ç¡®ä¿LM StudioæœåŠ¡å™¨æ­£åœ¨è¿è¡Œä¸”å·²åŠ è½½æ¨¡å‹ã€‚")
        sys.exit(0)
    
    # æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€
    if not tester.check_server_status():
        print("\nâŒ æ— æ³•è¿æ¥åˆ°LM StudioæœåŠ¡å™¨ï¼Œè¯·ç¡®ä¿:")
        print("   1. LM Studioå·²å¯åŠ¨")
        print("   2. å·²åŠ è½½æ¨¡å‹")
        print("   3. æœåŠ¡å™¨åœ°å€æ­£ç¡®")
        print("   4. ç«¯å£æœªè¢«å ç”¨")
        sys.exit(1)
    
    # æ ¹æ®å‚æ•°è¿è¡Œç›¸åº”æµ‹è¯•
    try:
        if args.test_type == "single":
            run_single_test(tester)
        elif args.test_type == "batch":
            run_batch_test(tester)
        elif args.test_type == "concurrent":
            run_concurrent_test(tester)
        elif args.test_type == "stress":
            run_stress_test(tester)
        elif args.test_type == "comprehensive":
            run_comprehensive_test(tester)
        
        print("\nâœ… æ‰€æœ‰æµ‹è¯•å®Œæˆ!")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
        if tester.metrics_history:
            print("ğŸ“Š ç”Ÿæˆå·²å®Œæˆæµ‹è¯•çš„æŠ¥å‘Š...")
            tester.print_report()
            tester.save_detailed_results()
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()